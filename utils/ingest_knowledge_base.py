import os
import uuid
import re
import fitz  # PyMuPDF
import qdrant_client

from sentence_transformers import SentenceTransformer
from tqdm import tqdm
from utils.llm_helper import SYSTEM_USAGE_KNOWLEDGE

KNOWLEDGE_BASE_DIR = "k_base"
QDRANT_HOST = "qdrant"
QDRANT_PORT = 6333
EMBEDDING_MODEL_NAME = 'intfloat/multilingual-e5-large'
COLLECTION_NAME = "rtarf_knowledge_base"  
CHUNK_SIZE_LINES = 15
BATCH_SIZE_EMBEDDING = 32

def clean_text(text: str) -> str:

    text = text.replace('\n', ' ').strip()
    text = re.sub(r'\s+', ' ', text)
    return text

def process_pdf_file(file_path: str) -> list[dict]:
    
    chunks_with_metadata = []
    filename = os.path.basename(file_path)
    try:
        doc = fitz.open(file_path)
        print(f"üìÑ Processing '{filename}'...")
        for page_num, page in enumerate(tqdm(doc, desc=f"  -> Pages in {filename}", leave=False)):
            text = page.get_text("text")
            if not text.strip(): continue
            lines = [line.strip() for line in text.split('\n') if line.strip()]
            for i in range(0, len(lines), CHUNK_SIZE_LINES):
                chunk_lines = lines[i:i + CHUNK_SIZE_LINES]
                chunk_text = " ".join(chunk_lines)
                cleaned_chunk = clean_text(chunk_text)
                if len(cleaned_chunk) > 50:
                    chunks_with_metadata.append({
                        "text": cleaned_chunk,
                        "source_file": filename,
                        "page_number": page_num + 1
                    })
        doc.close()
        print(f"‚úÖ Finished '{filename}', found {len(chunks_with_metadata)} valid chunks.")
    except Exception as e:
        print(f"‚ùå Error processing file {filename}: {e}")
    return chunks_with_metadata


def process_system_manual() -> list[dict]:
    
    if not SYSTEM_USAGE_KNOWLEDGE:
        return []
        
    print("‚öôÔ∏è  Processing internal system manual...")
    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÜ ‡∏ï‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏•‡∏±‡∏Å (##) ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ chunking
    chunks = [f"##{chunk}".strip() for chunk in SYSTEM_USAGE_KNOWLEDGE.split('##') if chunk.strip()]
    payloads = []
    for chunk in chunks:
        payloads.append({
            "text": chunk,
            "source_file": "system_manual", # ‡∏£‡∏∞‡∏ö‡∏∏‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏û‡∏¥‡πÄ‡∏®‡∏©‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠
            "page_number": 1
        })
    print(f"‚úÖ Finished 'system_manual', found {len(payloads)} chunks.")
    return payloads

def initialize_knowledge_base(force_recreate: bool = False):
   
    print("--- Initializing Knowledge Base ---")
    try:
        qdrant_cli = qdrant_client.QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT, timeout=20)
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠
        qdrant_cli.get_collections()
        print("‚úÖ Successfully connected to Qdrant.")
    except Exception as e:
        print(f"‚ùå CRITICAL: Could not connect to Qdrant at {QDRANT_HOST}:{QDRANT_PORT}. Aborting. Error: {e}")
        return

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Collection ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    collection_exists = False
    try:
        qdrant_cli.get_collection(collection_name=COLLECTION_NAME)
        collection_exists = True
        print(f"‚ÑπÔ∏è Collection '{COLLECTION_NAME}' already exists.")
    except Exception:
        print(f"‚ö†Ô∏è Collection '{COLLECTION_NAME}' not found.")
        collection_exists = False

    # ‡∏ñ‡πâ‡∏≤‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà ‡∏´‡∏£‡∏∑‡∏≠ Collection ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£ Ingest
    if force_recreate or not collection_exists:
        if force_recreate:
            print("üî• Forcing recreation of the knowledge base...")
        else:
            print("üöÄ Starting ingestion process for new knowledge base...")

        # --- ‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠ Logic ‡∏Å‡∏≤‡∏£ Ingest ‡πÄ‡∏î‡∏¥‡∏°‡∏à‡∏≤‡∏Å‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô main() ---
        try:
            print("Loading Sentence Transformer model...")
            embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)
            vector_size = embedding_model.get_sentence_embedding_dimension()

            print(f"Recreating Qdrant collection: '{COLLECTION_NAME}'...")
            qdrant_cli.recreate_collection(
                collection_name=COLLECTION_NAME,
                vectors_config=qdrant_client.http.models.VectorParams(
                    size=vector_size,
                    distance=qdrant_client.http.models.Distance.COSINE
                ),
            )
            
            all_payloads = []
            all_payloads.extend(process_system_manual())
            if os.path.isdir(KNOWLEDGE_BASE_DIR):
                pdf_files = [f for f in os.listdir(KNOWLEDGE_BASE_DIR) if f.lower().endswith(".pdf")]
                for filename in pdf_files:
                    file_path = os.path.join(KNOWLEDGE_BASE_DIR, filename)
                    all_payloads.extend(process_pdf_file(file_path))

            if not all_payloads:
                print("‚ùå No content found to ingest.")
                return

            print(f"Embedding a total of {len(all_payloads)} text chunks...")
            all_texts = [p['text'] for p in all_payloads]
            embeddings = embedding_model.encode(all_texts, show_progress_bar=True, batch_size=BATCH_SIZE_EMBEDDING)

            print("Upserting data into Qdrant...")
            qdrant_cli.upsert(
                collection_name=COLLECTION_NAME,
                points=qdrant_client.http.models.Batch(
                    ids=[str(uuid.uuid4()) for _ in all_payloads],
                    vectors=embeddings.tolist(),
                    payloads=all_payloads
                ),
                wait=True
            )
            print("--- ‚úÖ Knowledge Base Ingestion Process Completed! ---")

        except Exception as e:
            print(f"‚ùå An error occurred during the ingestion process: {e}")
    else:
        print("--- Knowledge Base is up-to-date. No action needed. ---")

if __name__ == "__main__":
    initialize_knowledge_base(force_recreate=True)