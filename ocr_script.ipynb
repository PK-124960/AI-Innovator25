{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0f16485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymupdf requests tqdm\n",
    "\n",
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import base64\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db127a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_page_to_base64(pdf_path, page_number):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page = doc.load_page(page_number)\n",
    "    pix = page.get_pixmap(dpi=300)\n",
    "    return base64.b64encode(pix.tobytes(\"png\")).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ea86795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_with_ollama(image_base64):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": \"scb10x/typhoon-ocr-7b:latest\",\n",
    "        \"prompt\": \"‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\",\n",
    "        \"images\": [image_base64]\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=payload, stream=True)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    full_text = \"\"\n",
    "    for line in response.iter_lines():\n",
    "        if line:\n",
    "            data = json.loads(line.decode(\"utf-8\"))\n",
    "            full_text += data.get(\"response\", \"\")\n",
    "\n",
    "    return full_text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e767036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_input(text):\n",
    "\n",
    "    text = re.sub(r'[\"\\']?natural_text[\"\\']?\\s*:\\s*', '', text)\n",
    "    text = re.sub(r'[{}\"]+', '', text)\n",
    "    \n",
    "    # ‡∏ï‡∏±‡∏î‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤ '‡πë.' ‡∏ó‡∏¥‡πâ‡∏á\n",
    "    start = re.search(r\"(‡πë\\..+)\", text, re.DOTALL)\n",
    "    if not start:\n",
    "        return \"\"\n",
    "    text = start.group(1)\n",
    "\n",
    "    # ‡∏ï‡∏±‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏à‡∏≠ \"‡∏à‡∏∂‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠\" ‡∏´‡∏£‡∏∑‡∏≠ \"‡∏à‡∏∂‡∏á‡πÄ‡∏™‡∏ô‡∏≠‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠\"\n",
    "    cutoff_match = re.search(r\"(.*?)\\b(‡∏à‡∏∂‡∏á(‡πÄ‡∏£‡∏µ‡∏¢‡∏ô|‡πÄ‡∏™‡∏ô‡∏≠)‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠.*?)$\", text, re.DOTALL)\n",
    "    if cutoff_match:\n",
    "        text = cutoff_match.group(1).strip()\n",
    "\n",
    "    # ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠ ‡πë ‚Äì ‡πî ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏¥‡∏°\n",
    "    part1 = re.search(r\"(‡πë\\.\\s*(‡∏î‡πâ‡∏ß‡∏¢|‡∏ï‡∏≤‡∏°‡∏≠‡πâ‡∏≤‡∏á‡∏ñ‡∏∂‡∏á).*?)(?=\\n\\s*‡πí\\.|$)\", text, re.DOTALL)\n",
    "    part2 = re.search(r\"(‡πí\\..*?)(?=\\n\\s*‡πì\\.|$)\", text, re.DOTALL)\n",
    "    part3 = re.search(r\"(‡πì\\..*?)(?=\\n\\s*‡πî\\.|$)\", text, re.DOTALL)\n",
    "    part4 = re.search(r\"(‡πî\\..*)\", text, re.DOTALL)\n",
    "\n",
    "    parts = []\n",
    "    if part1: parts.append(part1.group(1).strip())\n",
    "    if part2: parts.append(part2.group(1).strip())\n",
    "    if part3: parts.append(part3.group(1).strip())\n",
    "    if part4: parts.append(part4.group(1).strip())\n",
    "\n",
    "    # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ç‡πâ‡∏≠ ‡πë ‡πÅ‡∏•‡∏∞ ‡πí ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢\n",
    "    if len(parts) < 2:\n",
    "        return \"\"\n",
    "\n",
    "    return \" \".join(parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242f18cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_output(text):\n",
    "    # ‡∏•‡∏ö noise ‡πÄ‡∏ä‡πà‡∏ô \"natural_text\": ‡∏´‡∏£‡∏∑‡∏≠ JSON\n",
    "    text = re.sub(r'[\"\\']?natural_text[\"\\']?\\s*:\\s*', '', text)\n",
    "    text = re.sub(r'[{}\"]+', '', text)\n",
    "\n",
    "    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å '‡πë.' ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏£‡∏¥‡∏á\n",
    "    start_match = re.search(r\"(‡πë\\.\\s*(‡∏î‡πâ‡∏ß‡∏¢|‡∏ï‡∏≤‡∏°‡∏≠‡πâ‡∏≤‡∏á‡∏ñ‡∏∂‡∏á).*?)\", text, re.DOTALL)\n",
    "    if not start_match:\n",
    "        return \"\"\n",
    "\n",
    "    text = text[start_match.start():]\n",
    "\n",
    "    # ‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏µ‡πà '‡πí.' ‡∏´‡∏£‡∏∑‡∏≠ '‡∏à‡∏∂‡∏á‡πÄ‡∏™‡∏ô‡∏≠‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠' ‡∏´‡∏£‡∏∑‡∏≠ '‡∏à‡∏∂‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠'\n",
    "    stop_match = re.search(r\"(.*?)\\n\\s*(‡πí\\.\\s*(‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ|‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠ ‡πë).*?)\", text, re.DOTALL)\n",
    "    if stop_match:\n",
    "        return stop_match.group(1).strip()\n",
    "\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2044ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_dir = \"./GovernmentDocs\"\n",
    "output_dir = \"./ocr_json\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b23cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57dadd399eb84ba3bc08055f438c4978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîÑ Processing PDF files:   0%|          | 0/42 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000.pdf\n",
      " ‚úÖ The Outgoing letter of 000.pdf has been converted to image\n",
      " ‚úÖ The Incoming letter of 000.pdf has been converted to image\n",
      " ‚úÖ The Outgoing letter of 000.pdf is done with text extraction\n",
      " ‚úÖ The Incoming letter of 000.pdf is done with text extraction\n",
      " ‚úÖ The Outgoing letter of 000.pdf is done with text filtering\n",
      " ‚úÖ The Incoming letter of 000.pdf is done with text filtering\n",
      "‚úÖ Saved: ./ocr_json\\000.json\n",
      "001.pdf\n",
      " ‚úÖ The Outgoing letter of 001.pdf has been converted to image\n",
      " ‚úÖ The Incoming letter of 001.pdf has been converted to image\n",
      " ‚úÖ The Outgoing letter of 001.pdf is done with text extraction\n",
      " ‚úÖ The Incoming letter of 001.pdf is done with text extraction\n",
      " ‚úÖ The Outgoing letter of 001.pdf is done with text filtering\n",
      " ‚úÖ The Incoming letter of 001.pdf is done with text filtering\n",
      "‚úÖ Saved: ./ocr_json\\001.json\n",
      "002.pdf\n",
      " ‚úÖ The Outgoing letter of 002.pdf has been converted to image\n",
      " ‚úÖ The Incoming letter of 002.pdf has been converted to image\n",
      " ‚úÖ The Outgoing letter of 002.pdf is done with text extraction\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "file_list = [f\"{i:03}.pdf\" for i in range(1000)]\n",
    "file_list = [f for f in file_list if os.path.exists(os.path.join(pdf_dir, f))]\n",
    "\n",
    "for pdf_name in tqdm(file_list, desc=\"üîÑ Processing PDF files\", unit=\"file\"):\n",
    "    print(pdf_name)\n",
    "    pdf_path = os.path.join(pdf_dir, pdf_name)\n",
    "    output_json = os.path.join(output_dir, pdf_name.replace(\".pdf\", \".json\"))\n",
    "\n",
    "    try:\n",
    "        # Page check\n",
    "        with fitz.open(pdf_path) as doc:\n",
    "            if doc.page_count != 2:\n",
    "                print(f\"‚ö†Ô∏è Skip {pdf_name} (has {doc.page_count} pages)\")\n",
    "                continue\n",
    "\n",
    "        image_output = pdf_page_to_base64(pdf_path, 0)\n",
    "        print(f\" ‚úÖ The Outgoing letter of {pdf_name} has been converted to image\")\n",
    "        image_input = pdf_page_to_base64(pdf_path, 1)\n",
    "        print(f\" ‚úÖ The Incoming letter of {pdf_name} has been converted to image\")\n",
    "\n",
    "        output_text = ocr_with_ollama(image_output)\n",
    "        print(f\" ‚úÖ The Outgoing letter of {pdf_name} is done with text extraction\")\n",
    "        input_text = ocr_with_ollama(image_input)\n",
    "        print(f\" ‚úÖ The Incoming letter of {pdf_name} is done with text extraction\")\n",
    "\n",
    "        output_text = extract_output(output_text)\n",
    "        print(f\" ‚úÖ The Outgoing letter of {pdf_name} is done with text filtering\")\n",
    "        input_text = extract_input(input_text)\n",
    "        print(f\" ‚úÖ The Incoming letter of {pdf_name} is done with text filtering\")\n",
    "\n",
    "        result = {\n",
    "            \"file\": pdf_name,\n",
    "            \"input_text\": input_text,\n",
    "            \"output_text\": output_text\n",
    "        }\n",
    "\n",
    "        with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(result, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"‚úÖ Saved: {output_json}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in {pdf_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c09ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_path = \"./GovernmentDocs/000.pdf\"\n",
    "\n",
    "# image1 = pdf_page_to_base64(pdf_path, 1)  # ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏£‡∏±‡∏ö\n",
    "# image0 = pdf_page_to_base64(pdf_path, 0)  # ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏™‡πà‡∏á\n",
    "\n",
    "# print(\"üì§ Sending to Typhoon OCR (‡∏´‡∏ô‡πâ‡∏≤ 2)...\")\n",
    "# input_text = ocr_with_ollama(image1)\n",
    "\n",
    "# print(\"üì§ Sending to Typhoon OCR (‡∏´‡∏ô‡πâ‡∏≤ 1)...\")\n",
    "# output_text = ocr_with_ollama(image0)\n",
    "\n",
    "# print(\"üéØ Input:\", input_text[:200])\n",
    "# print(\"üéØ Output:\", output_text[:200])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
